<!DOCTYPE html>
<html lang="en-US"><head>
<title>Fuzzy Bayesianism - Miles Kodama</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description"
    content="Clearly real humans do not have sharp credences on most propositions of real interest outside of games and scientific experiments. Perfectly sharp credences are ruled out by both our computational and our evidential constraints. Even if I could access enough evidence to pin down a unique sharp posterior on some realistic proposition, my brain runs too slowly to update on all this evidence in reasonable time, and it&rsquo;s too small to hold the resulting infinitely precise credences in memory. ">
<link rel="canonical" href="https://mkodama.org/notes/fuzzy/" />


<link rel="icon" href="https://mkodama.org/favicon.ico" />


<link rel="apple-touch-icon" href="https://mkodama.org/touch-icon.png" />

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/modern-normalize/1.1.0/modern-normalize.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />










<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link rel="preload" as="style"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap" />
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC&display=swap" />
</noscript>






<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte.min.css">



<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte-options.min.css">

<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte-override.css">

</head>
<body>


<article id="main">
  <section>
<h1 class="content-title">Fuzzy Bayesianism</h1></section>

  

  <section><p>Clearly real humans do not have sharp credences on most propositions of real interest outside of games and scientific experiments. Perfectly sharp credences are ruled out by both our <em>computational</em> and our <em>evidential</em> constraints. Even if I could access enough evidence to pin down a unique sharp posterior on some realistic proposition, my brain runs too slowly to update on all this evidence in reasonable time, and it&rsquo;s too small to hold the resulting infinitely precise credences in memory. On the other hand, even an ideal Bayesian with infinite memory wouldn&rsquo;t be able to justify a unique sharp posterior just on the basis of evidence I can access. I simply don&rsquo;t know enough about the world to say non-arbitrarily that my credence on rain tomorrow should be 0.567… instead of 0.568…</p>
<p>Given that we all have these defects, we might wonder what mathematical formalism is appropriate for representing our fuzzy belief states. Sharp Bayesianism will judge all fuzzy believers like us irrational, but surely that&rsquo;s not the end of the story. There are better and worse ways of forming beliefs under scarcity of evidence and bounded compute. Maybe there are principles of fuzzy Bayesianism that guarantee our beliefs will be as good as they can be given our constraints.</p>
<p>So the big questions are:</p>
<ul>
<li>How should you formally represent a fuzzy belief?</li>
<li>How do you measure the accuracy of a fuzzy belief?<label for="sidenote-1" class="margin-toggle sidenote-number">(1)</label>
<input type="checkbox" id="sidenote-1" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(1)</span>ie, are there <a href="https://en.wikipedia.org/wiki/Scoring_rule">scoring rules</a> with desirable properties that don&rsquo;t assume precision?
</span>
</li>
<li>How should you update fuzzy beliefs when you receive new evidence?</li>
<li>How do you act on a fuzzy belief?</li>
</ul>
<h3 id="representing-fuzzy-beliefs">
Representing fuzzy beliefs
<a href="#representing-fuzzy-beliefs" class="heading-anchor">#</a>
</h3>
<p>A sharp Bayesian has a single credence function that takes in any proposition and returns a probability. A fuzzy Bayesian, by contrast, has a <em>set</em> of credence functions called a representor. Each function in the representor has to be normalized, non-negative, and countably additive, but the functions aren&rsquo;t required to agree with each other.</p>
<p>Why would you think this is a reasonable model of fuzzy belief given that no real person carries a list of explicit credence functions around in their head? The answer is that realistic fuzzy agents can be represented as though they had representors.</p>
<p>Suppose we have an agent capable of saying, for some pairs of propositions, whether one proposition is at least as subjectively credible as the other. That is, they have a credibility relation <code>$\trianglelefteq$</code> on the set of all propositions, and that relation may or may not be complete or transitive. Suppose also that there&rsquo;s a partial order relation <code>$\trianglelefteq'$</code> on the set of all propositions such that</p>
<ul>
<li><code>$A \trianglelefteq B \implies A \trianglelefteq' B.$</code> (<code>$\trianglelefteq'$</code> always agrees with <code>$\trianglelefteq.$</code>)</li>
<li>If <code>$A \trianglelefteq B$</code> and <code>$B \not\trianglelefteq A,$</code> then <code>$B \not\trianglelefteq' A.$</code> (<code>$\trianglelefteq'$</code> never makes two propositions equally credible if <code>$\trianglelefteq$</code> said only that one was at least as credible as the other.)</li>
<li><code>$\trianglelefteq'$</code> is complete, transitive, and <a href="https://en.wikipedia.org/wiki/Continuous_poset">continuous</a>.</li>
</ul>
<p>Then it&rsquo;s possible to represent our agent as a fuzzy Bayesian who judges one proposition at least as credible as another if an only if all the functions in their representor agree the more credible proposition is more likely than the less credible one.<label for="sidenote-2" class="margin-toggle sidenote-number">(2)</label>
<input type="checkbox" id="sidenote-2" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(2)</span>See Bradley <a href="https://personal.lse.ac.uk/bradleyr/pdf/Decision%20theory%20with%20a%20human%20face.pdf"><em>DT w/ HF</em></a> §11.5.2
</span>
 More formally, the conditions above imply that there exists a maximal set <code>$P$</code> of probability functions such that
<code>\[A \trianglelefteq B \iff p(A) \le p(B)\;\forall p\in P.\]</code></p>
<p>I think this theorem gives us a pretty good reason to trust the formalism of fuzzy Bayesianism. Even if your representor isn&rsquo;t part of your &ldquo;mental furniture,&ldquo;<label for="sidenote-3" class="margin-toggle sidenote-number">(3)</label>
<input type="checkbox" id="sidenote-3" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(3)</span>Ahmed <a href="https://www.cambridge.org/core/books/evidence-decision-and-causality/evidence-decision-and-causality/D58D014B0AEE742946D0265914047645"><em>ED&amp;C</em></a> §1.4
</span>
 we can accurately model you <em>as if</em> your probabalistic judgements were arrived at by consulting a representor—at least unless you&rsquo;re severely inconsistent.</p>
<h3 id="updating-fuzzy-beliefs">
Updating fuzzy beliefs
<a href="#updating-fuzzy-beliefs" class="heading-anchor">#</a>
</h3>
<p>The standard procedure for revising fuzzy beliefs when you gain new evidence is to update each of the credences in your representor by normal conditionalization. That is, if your representor at time <code>$t$</code> is <code>$P_t$</code>, and between <code>$t$</code> and <code>$t'$</code> you learn only that proposition <code>$E$</code> is true, then your representor at time <code>$t'$</code>should be
<code>\[P_{t'} = \{p(\cdot |E)\,|\, p \in P_t\}\]</code></p>
<p>There&rsquo;s some writing about <em>why</em> this updating procedure is rationally required, but I don&rsquo;t find it terribly interesting as I&rsquo;m not tempted to reject conditionalization in either the sharp or the fuzzy case.<label for="sidenote-4" class="margin-toggle sidenote-number">(4)</label>
<input type="checkbox" id="sidenote-4" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(4)</span>This <a href="https://link.springer.com/article/10.1007/s11098-019-01377-y">article by Pettigrew</a> makes the case for sharp Bayesians to update by conditionalization. I also recommend his interview on the <a href="https://open.spotify.com/episode/0k6D9eKwpwAt93AtK1mqPC?si=42f7858f767c4075">Formal Philosophy Podcast</a>.
</span>
</p>
<p><em>Questions</em></p>
<ul>
<li>Are there cases where it&rsquo;s intutitively appealing for a fuzzy Bayesian to not conditionalize on new evidence?</li>
</ul>
<p><em>Reading List</em></p>
<ul>
<li>Mahtani&rsquo;s <a href="https://philarchive.org/archive/MAHIP">overview</a> of imprecise probabilities ✔</li>
<li>Seamus Bradley&rsquo;s <a href="https://plato.stanford.edu/entries/imprecise-probabilities/"><em>SEP</em> article</a></li>
<li>Richard Bradley, <a href="https://personal.lse.ac.uk/bradleyr/pdf/Decision%20theory%20with%20a%20human%20face.pdf"><em>DT with a Human Face</em></a> chapter 11. ✔</li>
<li>Elga <a href="https://www.princeton.edu/~adame/papers/sharp/elga-subjective-probabilities-should-be-sharp.pdf">presents a Dutch book</a> against agents with fuzzy credences.</li>
</ul>
<p><em>Last updated 3 September 2024</em></p>
</section>
  <section><footer class="page-footer">
<hr />

<div class="previous-post" style="display:inline-block;">
  
  <a class="link-reverse" href="https://mkodama.org/notes/moral-uncertainty/?ref=footer">« Moral Uncertainty</a>
  
</div>

<div class="next-post", style="display:inline-block;float:right;">
  
  <a class="link-reverse" href="https://mkodama.org/notes/dodgson-con/?ref=footer">Dodgson Condensation »</a>
  
</div>

<ul class="page-footer-menu">
  
  
  
  

  

  

  

  

  

  

  

  

  

  

  
  
  
    <li><a href="https://mailchi.mp/9d6b52ea249e/mkodama-newsletter"> Subscribe</a></li>
  
    <li><a href="mailto:miles@mkodama.org"> Email</a></li>
  
</ul>





</footer>
</section>
  <section><nav class="menu">
    <ul>
    
        <li><a href="https://mkodama.org/">Home</a></li>
    
        <li><a href="https://mkodama.org/posts/">Posts</a></li>
    
        <li><a href="https://mkodama.org/notes/">Notes</a></li>
    
        <li><a href="https://mkodama.org/categories/">Categories</a></li>
    
        <li><a href="https://mkodama.org/about/">About</a></li>
    
    </ul>
</nav>
</section>
</article>







  <script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&!t.classList.contains("nolatex")&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script>


<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" crossorigin="anonymous">
<script defer src="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" crossorigin="anonymous"></script>
<script defer src="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            
            
            
            
            
            
            trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
            macros: {
              "\\eqref": "\\href{###1}{(\\text{#1})}",
              "\\ref": "\\href{###1}{\\text{#1}}",
              "\\label": "\\htmlId{#1}{}"
            }
        });
    });
</script>



</body>

</html>
