<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Miles Kodama</title>
    <link>https://mkodama.org/</link>
    <description>Recent content in Home on Miles Kodama</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 19 Jul 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mkodama.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Anthropic and Decision-Theoretical Dutch Books</title>
      <link>https://mkodama.org/posts/dutchbooks/</link>
      <pubDate>Fri, 19 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/dutchbooks/</guid>
      <description>Introduction # Here&amp;rsquo;s a fun fact—some combinations of anthropic assumptions and decision theories expose you to Dutch books.(1) (1)My apologies to readers who aren&amp;rsquo;t familiar with the basics of the anthropics and decision theory debates; I won&amp;rsquo;t be explaining them here. For an introduction to causal and evidential decision theory, I recommend chapter nine of Martin Peterson&amp;rsquo;s textbook, and for a (dated) intro to anthropics, I recommend Nick Bostrom&amp;rsquo;s Anthropic Bias.</description>
    </item>
    <item>
      <title>Defining Psychological Connectedness</title>
      <link>https://mkodama.org/posts/reductionist/</link>
      <pubDate>Sun, 02 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/reductionist/</guid>
      <description>Motivation # What does it mean for a future being to be the same person I am now? How can we claim that someone in 2024 is still the same person they were in 2014 in spite of all the physical and psychological changes they&amp;rsquo;ve undergone in the meantime? I think the best answers to these questions rely on a reductionist view of personal identity, according to which two minds belong to the same person just in case they share certain psychological connections.</description>
    </item>
    <item>
      <title>Landmark Numbers</title>
      <link>https://mkodama.org/posts/numbers/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/numbers/</guid>
      <description>Motivation # You are awash in numbers. You read them in news articles, hear them in conversations, ponder over them in textbooks. The half-life of carbon 14 is 5700 years. The cruising speed of a Boeing 747 is 900 kilometers per hour. The diameter of a Covid-19 particle is 80 nanometers. Your response to this torrent of numbers could be to let it flow past without leaving much impression on your brain.</description>
    </item>
    <item>
      <title>Let Students Use AI</title>
      <link>https://mkodama.org/posts/dunbar/</link>
      <pubDate>Fri, 09 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/dunbar/</guid>
      <description>I originally wrote this post for an essay contest at my school. It won the third place prize and was published in a campus magazine under a slightly different title. I&amp;rsquo;ll admit that my discussion is rather parochial in its focus on Williams, but my main claims easily generalize to other institutions. As always, I invite comments, objections, and feedback.&#xA;Williams is due for a deep rethink on the role of artificial intelligence (hereafter AI) in college classes.</description>
    </item>
    <item>
      <title>Wear a Nametag</title>
      <link>https://mkodama.org/posts/nametag/</link>
      <pubDate>Fri, 02 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/nametag/</guid>
      <description>I&amp;rsquo;ve been wearing a nametag out in public (as often as I can remember to put it on) for the last three months, and I think you should consider doing the same. ⊕ Your nametag doesn’t have to be fancy. As you can see, mine isn’t. Why? # Remind acquaintances of your name. I have upwards of a hundred acquaintances I can recognize on sight and whom I&amp;rsquo;ve spoken to at least once whose names I cannot recall.</description>
    </item>
    <item>
      <title>Fooled by Randomness</title>
      <link>https://mkodama.org/posts/taleb-randomness/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/posts/taleb-randomness/</guid>
      <description>Main points # I take this book to be mainly about the expected value (EV) principle, which says that when you make a decision under risk, you should maximize your probability weighted average payoff. The concept of expected value makes only a brief appearance in one chapter, and you won&amp;rsquo;t find a mathematical formula for it anywhere in the book. But as Taleb says, “mathematics is a tool to meditate, not compute,” and most of what he writes in Fooled by Randomness is implicitly a meditation on EV.</description>
    </item>
    <item>
      <title>Dirac Notation</title>
      <link>https://mkodama.org/notes/dirac/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/dirac/</guid>
      <description>This note is a stub for now—more soon!&#xA;Questions # What are the advantages of Dirac notation over the mathematicians&amp;rsquo; notation for inner product spaces? Reading List # Dirac&amp;rsquo;s original paper, &amp;ldquo;A new notation for quantum mechanics&amp;rdquo; ✔ Chapter 1 from Andre Lukas&amp;rsquo;s notes on mathematical methods for physicists ✔ Sakurai&amp;rsquo;s Modern Quantum Mechanics §1.2 Chapter 3 from Griffiths and Schroeter&amp;rsquo;s Intro to QM Last updated 5 September 2024</description>
    </item>
    <item>
      <title>Dodgson Condensation</title>
      <link>https://mkodama.org/notes/dodgson-con/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/dodgson-con/</guid>
      <description>The Reverend Charles Dodgson (alias Lewis Carroll) invented a neat method of taking determinants without cofactor expansion or row reduction. I like to think of his condensation method as building an imaginary pyramid of matrices. The base of the pyramid is the matrix whose determinant you&amp;rsquo;re trying to find. In the air above each of the base matrix&amp;rsquo;s interior whitespaces, you imagine writing the determinant of the two-by-two submatrix centered on that whitespace.</description>
    </item>
    <item>
      <title>Fuzzy Bayesianism</title>
      <link>https://mkodama.org/notes/fuzzy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/fuzzy/</guid>
      <description>Clearly real humans do not have sharp credences on most propositions of real interest outside of games and scientific experiments. Perfectly sharp credences are ruled out by both our computational and our evidential constraints. Even if I could access enough evidence to pin down a unique sharp posterior on some realistic proposition, my brain runs too slowly to update on all this evidence in reasonable time, and it&amp;rsquo;s too small to hold the resulting infinitely precise credences in memory.</description>
    </item>
    <item>
      <title>Moral Uncertainty</title>
      <link>https://mkodama.org/notes/moral-uncertainty/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/moral-uncertainty/</guid>
      <description>Maximizing Expected Choiceworthiness seems reasonable on its face, but I have three worries.&#xA;(1) I&amp;rsquo;m not sure that the best reasons we have to maximize expected value in cases of empirical uncertainty generalize to the case of moral uncertainty. For example, Law of Large Numbers arguments don&amp;rsquo;t apply if the event that you&amp;rsquo;re uncertain about is by its nature unrepeatable.&#xA;(2) It&amp;rsquo;s a very strict constraint on a moral theory to say it must rate all possible actions one might take with a single real number.</description>
    </item>
    <item>
      <title>Suffering-Focused Ethics</title>
      <link>https://mkodama.org/notes/sfe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/sfe/</guid>
      <description>There&amp;rsquo;s a cluster of ethical views that say the prevention of extreme suffering takes priority over all other goals. On some views, preference satisfaction, pleasure creation, and the like are still considered good, but suffering reduction takes lexical priority over them, or is at least so much more desirable that it crowds out these other goals in practice. Other suffering-focused views go further and deny that pleasure and preference satisfaction are good at all.</description>
    </item>
    <item>
      <title>The Yankees Decision Problem</title>
      <link>https://mkodama.org/notes/yankees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mkodama.org/notes/yankees/</guid>
      <description>This scenario is supposed to counter the Why ain&amp;rsquo;cha rich? argument for EDT by showing that causalists can predictably out-earn evidentialists when faced with the right sort of game.&#xA;In Arntzenius&amp;rsquo;s original statement, the Red Sox and the Yankees are going to play a long series of games against each other, and it&amp;rsquo;s known that the Yankees have a 90% chance of winning each game. The (apparently ill-informed) oddsmakers are offering two bets on the games: a bet that pays out $1 if the Yankees win and loses $2 if the Red Sox win, and a bet that pays out $2 if the Red Sox win and loses $1 if the Yankees win.</description>
    </item>
  </channel>
</rss>
