<!DOCTYPE html>
<html lang="en-US"><head>
<title>Fooled by Randomness - Miles Kodama</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description"
    content="Nassim Taleb&#39;s paean to the expected value principle ">
<link rel="canonical" href="https://mkodama.org/posts/taleb-randomness/" />


<link rel="icon" href="https://mkodama.org/favicon.ico" />


<link rel="apple-touch-icon" href="https://mkodama.org/touch-icon.png" />

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/modern-normalize/1.1.0/modern-normalize.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />










<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link rel="preload" as="style"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap" />
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC&display=swap" />
</noscript>






<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte.min.css">



<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte-options.min.css">

<link rel="stylesheet" href="https://mkodama.org/css/hugo-tufte-override.css">

</head>
<body>


<article id="main">
  <section>
<h1 class="content-title">Fooled by Randomness</h1><span class="content-meta"><p class="date">2024-01-20</p><span>11 min read&nbsp;</span></span></section>

  
<section>
  <details closed class="toc">
    <summary>Table of Contents</summary>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#main-points">Main points</a></li>
    <li><a href="#miscellaneous">Miscellaneous</a></li>
    <li><a href="#in-context">In context</a></li>
  </ul>
</nav>
  </details>
</section>


  <section><h2 id="main-points">
Main points
<a href="#main-points" class="heading-anchor">#</a>
</h2>
<p>I take this book to be mainly about the expected value (EV) principle, which says that when you make a decision under risk, you should maximize your probability weighted average payoff. The concept of expected value makes only a brief appearance in one chapter, and you won&rsquo;t find a mathematical formula for it anywhere in the book. But as Taleb says, “mathematics is a tool to meditate, not compute,” and most of what he writes in <em>Fooled by Randomness</em> is implicitly a meditation on EV. <label for="sidenote-1" class="margin-toggle sidenote-number">(1)</label>
<input type="checkbox" id="sidenote-1" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(1)</span>Pg 234. All page numbers refer to the <a href="https://www.penguinrandomhouse.com/books/605747/incerto-5-book-bundle-by-nassim-nicholas-taleb/boxedset/">updated second edition</a> published by Random House in 2021.
</span>
</p>
<p>A natural first question is why we should care about EV or want to maximize it in the first place. If a bet turns out to win you a profit, why does it matter whether the value of taking that bet was positive or negative in expectation? You won, so what more is there to discuss? Or suppose, on the other hand, that you place a bet and lose. Is it really much consolation to be told that your EV was positive? Why should it matter to you that your choice was <em>rational</em> given that it turned out to be wrong?</p>
<p>For one, there are strong <a href="https://jc.gatspress.com/pdf/on_expected_utility.pdf">decision-theoretic reasons</a> why you should maximize EV. It turns out that all agents whose beliefs and preferences satisfy certain (surprisingly weak) coherence properties are mathematically <em>forced</em> to maximize EV, but this is not the kind of argument that Taleb goes in for. Rather, he appeals to ergodicity, the principle that in the long run, EV maximization is guaranteed to outperform any other strategy.<label for="sidenote-2" class="margin-toggle sidenote-number">(2)</label>
<input type="checkbox" id="sidenote-2" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(2)</span>Ppg 57-58.
</span>
 You could think of this as saying that over the course of a sufficiently long career, a trader who follows the EV principle is guaranteed to do better than one who flouts it, or if you agree with Keynes about the long run,<label for="sidenote-3" class="margin-toggle sidenote-number">(3)</label>
<input type="checkbox" id="sidenote-3" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(3)</span>&ldquo;In the long run, we&rsquo;re all dead.&rdquo;
</span>
 a sufficently large trading firm is guaranteed to make the largest possible profit if it hires only EV maximizers.</p>
<p>But of course, noise can prevail over ergodicity in the short term, and although it is always rational to obey the EV principle, the principle&rsquo;s recommendations sometimes turn out to be wrong. Negative EV bets can sometimes pay off spectacularly, allowing bad traders to reap large profits. And when these traders succeed, firms will be sorely tempted to reward them. After all, the firm can&rsquo;t see what Taleb calls the &ldquo;generator,&rdquo; the full distribution of outcomes that could have happened:</p>
<blockquote>
<p>Unlike a well-defined, precise game like Russian roulette, where the risks are visible to anyone capable of multiplying and dividing by six, one does not observe the barrel of reality.<label for="sidenote-4" class="margin-toggle sidenote-number">(4)</label>
<input type="checkbox" id="sidenote-4" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(4)</span>Pg 26.
</span>
</p>
</blockquote>
<p>But it is the invisible generator that determines whether a choice was rational or irrational. If you consider only the actual outcome and none of the merely possible outcomes, you will end up rewarding whatever choices happened to be right, regardless of whether they were wise in expectation. In other words, you will be fooled by randomness.</p>
<p>As Taleb points out, this happens all the time. We routinely assume that right decisions are always rational and wrong decisions always irrational. As an example, he picks on the journalist George Will for arguing, in an interview with the economist Robert Shiller, that</p>
<blockquote>
<p>had people listen to him [Shiller] in the past, they would have lost money, as the market has more than doubled since he started pronouncing it overvalued. To such a journalistic and well-sounding (but senseless) argument, Shiller was unable to respond, except to explain that the fact that he was wrong in one single market call should not carry undue significance. <label for="sidenote-5" class="margin-toggle sidenote-number">(5)</label>
<input type="checkbox" id="sidenote-5" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(5)</span>Pg 35.
</span>
</p>
</blockquote>
<p>Taleb’s point is that Shiller was talking about the generator, not about the outcome. When he claimed that stocks were overvalued, he was saying that betting on a market rise was irrational, not that it was wrong. Even if stocks were, in expectation, worth less than the prices they were selling at, they could very well still go up, and indeed they did. A single observation does not conclusively prove anything about the generator. Again:</p>
<blockquote>
<p>I will repeat this point, until I get hoarse: a mistake is not something to be determined after the fact, but in light of the information until that point.<label for="sidenote-6" class="margin-toggle sidenote-number">(6)</label>
<input type="checkbox" id="sidenote-6" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(6)</span>Pg 56.
</span>
</p>
</blockquote>
<p>Why does Taleb have to keep saying this? Why do most people find the EV principle so unintuitive? One reason, he thinks, is that our mental machinery blinds us to probability. We simply cannot picture expected values, which makes it nigh on impossible for us to weigh them against each other:</p>
<blockquote>
<p>Consider a bet you make with a colleague for the amount of $1000, which, in your opinion, is exactly fair. Tomorrow night, you will have zero or $2000 in your pocket, each with a 50% probability. [The expected value of your bet is $1000, yet] can you imagine (that is visualize, not compute, mathematically) the value being $1000? We can conjure up one and only one state at a given time, i.e., either 0 or $2000. Left to our own devices, we are likely to bet in an irrational way, as one of the states would dominate the picture—the fear of ending with nothing or the excitement of an extra $1000.<label for="sidenote-7" class="margin-toggle sidenote-number">(7)</label>
<input type="checkbox" id="sidenote-7" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(7)</span>Pg 183.
</span>
</p>
</blockquote>
<p>Perhaps you can approximate a linear combination of the two possible states by imagining the world where you win half of the time and imagining the world where you lose the other half of the time, but this is still not the same as imagining the two states at once as equally probable outcomes. And this technique still fails when you have to reason about truly Pascalian probabilities. If I thought about situations in which I win the lottery in proportion to my true probability of winning, I would spend even less time than I do in the status quo—which is barely any—thinking about that possibility, leading me to round it to zero.</p>
<p>But overcoming your probability blindness is only half the battle. In order to properly follow the EV principle, you also have to consider the relative sizes of your payouts in all possible worlds. This sounds trivial, but as Taleb points out, people mess it up all the time when they invest solely on the basis of whether they’re bullish or bearish, ie, the direction they expect the market to move:</p>
<blockquote>
<p>&ldquo;Are you bullish or are you bearish?&rdquo; I was asked by the strategist. I replied that I could not understand the words <em>bullish</em> and <em>bearish</em> outside of their purely zoological consideration…My opinion was that the market was more likely to go up (&ldquo;I would be bullish”), but that it was preferable to short it (“I would be bearish”), because, in the event of its going down, it could go down a lot. <label for="sidenote-8" class="margin-toggle sidenote-number">(8)</label>
<input type="checkbox" id="sidenote-8" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(8)</span>Pg 101.
</span>
</p>
</blockquote>
<p>The same confusion is at play when people interpret <a href="https://www.lesswrong.com/posts/jiBFC7DcCrZjGmZnJ/conservation-of-expected-evidence?utm_campaign=post_share&amp;utm_source=link">conservation of expected evidence</a> to mean that you can’t predict the direction your credences will move when you see new evidence. In fact you can—it’s just your expected credence that must remain constant. Likewise, you can think that the market is more likely than not to rise while still thinking that it will be lower next week in expectation than it is now. This simple observation justifies Taleb’s own investment strategy of making bets that predictably lose, but are nevertheless positive EV.<label for="sidenote-9" class="margin-toggle sidenote-number">(9)</label>
<input type="checkbox" id="sidenote-9" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(9)</span>Pg 103.
</span>
</p>
<h2 id="miscellaneous">
Miscellaneous
<a href="#miscellaneous" class="heading-anchor">#</a>
</h2>
<p>The closest Taleb comes to giving investment advice is to say that you should check your portfolio&rsquo;s performance infrequently.<label for="sidenote-10" class="margin-toggle sidenote-number">(10)</label>
<input type="checkbox" id="sidenote-10" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(10)</span>Pg 66-67.
</span>
 In the short run, everything that you see is noise, so paying attention to it will stress you out needlessly, or worse, bait you into overreacting. Of course, the downside of this head-in-the-sand strategy is that you can’t react quickly enough to cut your losses if one of your positions starts to tank. That others are selling is usually some amount of evidence that you ought to sell as well, and Taleb says elsewhere that being married to your positions is the mark of a bad trader.<label for="sidenote-11" class="margin-toggle sidenote-number">(11)</label>
<input type="checkbox" id="sidenote-11" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(11)</span>Pg 92-93.
</span>
</p>
<p>Common sense and psychological research both agree that learning from the mistakes of others is mostly fake. This is part of why using a prediction market—or more generally, betting on your beliefs—is good for you. Most of our learning about chancy systems hapens on a visceral level, so if being wrong doesn’t hurt, you won’t remember it. You will be like the amnesiac who couldn&rsquo;t remember Dr Claparède&rsquo;s name for fifteen minutes but never forgot when he pricked her with a pin.<label for="sidenote-12" class="margin-toggle sidenote-number">(12)</label>
<input type="checkbox" id="sidenote-12" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(12)</span>Pg 53.
</span>
 The displeasure I feel when my predictions turn out to be wrong (and the shame of knowing that others can see I was wrong) are analogous to the pinprick. Without it, I may notice my mistakes on a conscious level, but I don&rsquo;t truly learn from them.</p>
<p>Taleb offers some sound advice for book buyers: ignore the praise you find printed on the back cover.<label for="sidenote-13" class="margin-toggle sidenote-number">(13)</label>
<input type="checkbox" id="sidenote-13" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(13)</span>Pg 161.
</span>
 Reviews chosen by the publisher only sway me if they come from a source whom I recognize and already hold in respect. There are so many “expert critics” out there that the monkey on a typewriter effect plus selection bias guarantees at least a few glowing reviews for any old trash. Note, however, that this does not apply to book reviews that <em>you</em> seek out. In that case, there&rsquo;s no filtering effect, so you can safely update on praise from unfamiliar sources.</p>
<p>Taleb also has some thoughts on why probability theory is such a young field:</p>
<blockquote>
<p>We had to wait until the emergence of the gambling literature to see the growth of the mathematics of probability. Popular belief holds that the religious backdrop of the first and second millennia blocked the growth of tools that hint at absence of determinism, and caused the delays in probability research. The idea is extremely dubious; we simply did not compute probabilities because we did not <em>dare</em> to? Surely the reason is rather because we did not <em>need</em> to.<label for="sidenote-14" class="margin-toggle sidenote-number">(14)</label>
<input type="checkbox" id="sidenote-14" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(14)</span>Pg 200.
</span>
</p>
</blockquote>
<p>Gambling is almost certainly part of the puzzle, but I&rsquo;m not sure it fully explains why probability theory developed so much later than other equally fundamental branches of math. Euclid was doing geometry centuries before the common era, and medieval Indian mathematicians knew all about Taylor series.<label for="sidenote-15" class="margin-toggle sidenote-number">(15)</label>
<input type="checkbox" id="sidenote-15" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(15)</span>See Victor Katz, <a href="https://edisciplinas.usp.br/pluginfile.php/6075667/mod_resource/content/1/Victor%20J.%20Katz%20-%20A%20History%20of%20Mathematics-Pearson%20%282008%29.pdf"><em>A History of Mathematics</em></a> § 8.7.
</span>
 Why did it take until the seventeenth century for Fermat and Pascal to even begin the study of probability and until the twentieth century for Kolmogorov to put it on a sound axiomatic footing? My very shallow take from skimming part of Ian Hacking&rsquo;s <a href="https://www.cambridge.org/core/books/emergence-of-probability/9852017A380C63DA30886D25B80336A7?utm_campaign=shareaholic&amp;utm_medium=copy_link&amp;utm_source=bookmark"><em>The Emergence of Probability</em></a> is that the advent of mass statistical record-keeping also had something to with it. These records, which first became available in the seventeenth century, raised questions such as <em>How likely is a fifty year old man to live to sixty?</em> or <em>Why is the number of suicides in London virtually the same every year?</em>—questions that you need probability theory to answer precisely.</p>
<h2 id="in-context">
In context
<a href="#in-context" class="heading-anchor">#</a>
</h2>
<p>Overall, I think this book would be an excellent introduction to the rationality literature for someone who hasn’t read <a href="https://us.macmillan.com/books/9780374533557/thinkingfastandslow"><em>Thinking, Fast and Slow</em></a> or the <a href="https://www.lesswrong.com/rationality"><em>Sequences</em></a>. Taleb&rsquo;s tone is a bit more formal and academic than Yudkowsky&rsquo;s, and a bit more casual than Kahneman&rsquo;s. His macho-intellectual trader vibes will likely appeal to readers interested in finance.</p>
<p>One difference between Taleb and these other authors is that he takes a dimmer view than they do on the possibility of self-improvement. All three of them agree that humans are systematically irrational, but Taleb is somewhat distinctive in claiming  &ldquo;we are flawed beyond repair.”<label for="sidenote-16" class="margin-toggle sidenote-number">(16)</label>
<input type="checkbox" id="sidenote-16" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(16)</span>Pg xliv.
</span>
 He&rsquo;s even more fatalistic near the end of the book:</p>
<blockquote>
<p>The epiphany I had in my career in randomness came when I understood that I was not intelligent enough, nor strong enough, to even try to fight my emotions.<label for="sidenote-17" class="margin-toggle sidenote-number">(17)</label>
<input type="checkbox" id="sidenote-17" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(17)</span>Pg 222.
</span>
</p>
</blockquote>
<p>Contrast this with Yudkowsky&rsquo;s motto of <a href="https://www.lesswrong.com/posts/DoLQN5ryZ9XkZjq5h/tsuyoku-naritai-i-want-to-become-stronger?utm_campaign=post_share&amp;utm_source=link"><em>tsuyoku naritai</em></a>. Yudkowsky agrees that he is not strong enough, but unlike Taleb, he declares it his ambition to become stronger, whereas Taleb thinks the rationalist struggle is a lost cause.</p>
<p>Another difference between them is that Yudkowsky is a scientist at heart, which makes <a href="https://www.lesswrong.com/posts/anCubLdggTWjnEvBS/your-rationality-is-my-business?utm_campaign=post_share&amp;utm_source=link">your rationality his business</a>. He doesn’t just think it’s possible for you to become stronger; he <em>wants</em> you to become stronger so that you can join in humanity&rsquo;s great quest for truth, or at least so that your stupidity doesn&rsquo;t lead to AI killing us all. On the other hand, Taleb is a trader, meaning that he makes his living off of others’ irrationality:</p>
<blockquote>
<p>My wish is for people in general to remain fools of randomness (so I can trade against them), yet for there to remain a minority intelligent enough to value my methods and hire my services.<label for="sidenote-18" class="margin-toggle sidenote-number">(18)</label>
<input type="checkbox" id="sidenote-18" class="margin-toggle"/>
<span class="sidenote">
<span class="sidenote-number">(18)</span>Ppg 41-42.
</span>
</p>
</blockquote>
<p>Odd, then, that he took it upon himself to write a popular book teaching the masses to be a bit less foolish.</p>
<p><em>Thank you to Warren Zhu for recommending the</em> Incerto <em>series to me.</em></p>
</section>
  <section><footer class="page-footer">
<hr />

<div class="previous-post" style="display:inline-block;">
  
</div>

<div class="next-post", style="display:inline-block;float:right;">
  
  <a class="link-reverse" href="https://mkodama.org/posts/nametag/?ref=footer">Wear a nametag »</a>
  
</div>

<ul class="page-footer-menu">
  
  
  
  

  

  

  

  

  

  

  

  

  

  

  
  
  
    <li><a href="https://mailchi.mp/9d6b52ea249e/mkodama-newsletter"> Subscribe</a></li>
  
    <li><a href="mailto:miles@mkodama.org"> Email</a></li>
  
    <li><a href="https://manifold.markets/MilesKodama"> Manifold</a></li>
  
</ul>





</footer>
</section>
  <section><nav class="menu">
    <ul>
    
        <li><a href="https://mkodama.org/">Home</a></li>
    
        <li><a href="https://mkodama.org/posts/">Posts</a></li>
    
        <li><a href="https://mkodama.org/categories/">Categories</a></li>
    
        <li><a href="https://mkodama.org/about/">About</a></li>
    
    </ul>
</nav>
</section>
</article>





</body>

</html>
